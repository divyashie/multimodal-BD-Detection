"""
Enhanced BD Detection Pipeline
Complete implementation integrating all improvements including balanced sampling
"""

import pickle
import logging
import torch
import numpy as np
import os
from datetime import datetime
from typing import Tuple, List, Dict
from collections import Counter
from torch.utils.data import DataLoader, WeightedRandomSampler

from configs.config import Config
from data.dataset import (
    ImprovedTemporalDataset,
    create_improved_data_loader,
    create_improved_user_split,
    analyze_data_distribution,
    suggest_hyperparameters,
    create_data_quality_dashboard
)
from models.multimodal_model import ImprovedMultimodalModel
from training.trainer import ImprovedTrainer
from training.evaluator import ImprovedEvaluator


def setup_logging() -> logging.Logger:
    log_filename = f'enhanced_pipeline_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename),
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger('BD_Detection_Pipeline')
    logger.info(f"Logging initialized. Log file: {log_filename}")
    return logger


def convert_to_serializable(obj):
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, torch.Tensor):
        return obj.cpu().numpy().tolist()
    elif isinstance(obj, dict):
        return {key: convert_to_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    elif hasattr(obj, '__dict__'):
        return convert_to_serializable(obj.__dict__)
    return obj


def setup_environment(logger: logging.Logger):
    logger.info("="*60)
    logger.info("üöÄ ENHANCED BD DETECTION PIPELINE INITIALIZATION")
    logger.info("="*60)
    try:
        Config.validate()
        logger.info("‚úÖ Configuration validation passed")
    except Exception as e:
        logger.error(f"‚ùå Configuration validation failed: {e}")
        raise

    for directory in ['results', 'models', 'plots', 'logs', 'checkpoints', 'visualizations']:
        os.makedirs(directory, exist_ok=True)
        logger.info(f"üìÅ Created/verified directory: {directory}")

    logger.info(f"üñ•Ô∏è  Device: {Config.device}")
    logger.info(f"üìä Data path: {Config.data_path}")
    logger.info(f"üîÑ Batch size: {Config.batch_size}")
    logger.info(f"üéØ Learning rate: {Config.learning_rate}")
    logger.info(f"üìà Max epochs: {Config.num_epochs}")

    if torch.cuda.is_available():
        logger.info(f"üéÆ CUDA available: {torch.cuda.get_device_name(0)}")
        logger.info(f"üíæ CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        logger.info(f"üî• PyTorch version: {torch.__version__}")
    else:
        logger.info("üñ•Ô∏è  Running on CPU")


def load_and_analyze_data(logger: logging.Logger) -> Tuple[List, Dict]:
    logger.info("\n" + "="*50)
    logger.info("üìä DATA LOADING AND ANALYSIS")
    logger.info("="*50)
    try:
        logger.info(f"Loading data from: {Config.data_path}")
        with open(Config.data_path, 'rb') as f:
            full_data = pickle.load(f)
        logger.info(f"‚úÖ Successfully loaded {len(full_data)} samples")
        logger.info("üîç Analyzing data distribution...")
        data_analysis = analyze_data_distribution(full_data)
        logger.info("üìà Creating data quality dashboard...")
        create_data_quality_dashboard(data_analysis)
        logger.info("\nüìä DATA STATISTICS:")
        if 'class_distribution' in data_analysis:
            for class_name, count in data_analysis['class_distribution'].items():
                logger.info(f"   {class_name}: {count} samples")
        if 'temporal_stats' in data_analysis:
            stats = data_analysis['temporal_stats']
            logger.info(f"   Average sequence length: {stats.get('avg_length', 'N/A'):.2f}")
            logger.info(f"   Min sequence length: {stats.get('min_length', 'N/A')}")
            logger.info(f"   Max sequence length: {stats.get('max_length', 'N/A')}")
        logger.info("üéõÔ∏è  Getting hyperparameter suggestions...")
        suggestions = suggest_hyperparameters(data_analysis)
        logger.info("üí° HYPERPARAMETER SUGGESTIONS:")
        for param, value in suggestions.items():
            logger.info(f"   {param}: {value}")
        return full_data, data_analysis
    except FileNotFoundError:
        logger.error(f"‚ùå Data file not found: {Config.data_path}")
        raise
    except Exception as e:
        logger.error(f"‚ùå Error loading data: {e}")
        raise


def create_balanced_sampler(dataset):
    labels = [dataset[i]['sequence_label'].item() for i in range(len(dataset))]
    class_counts = Counter(labels)
    weights_per_class = {cls: 1.0 / count for cls, count in class_counts.items()}
    sample_weights = [weights_per_class[label] for label in labels]

    sampler = WeightedRandomSampler(
        weights=sample_weights,
        num_samples=len(sample_weights),
        replacement=True
    )
    return sampler


def create_datasets_and_loaders(full_data, logger: logging.Logger):
    logger.info("\n" + "="*50)
    logger.info("üîÑ DATASET CREATION AND DATA LOADING")
    logger.info("="*50)
    try:
        logger.info("üë• Creating user-based data splits...")
        train_data, val_data, test_data = create_improved_user_split(full_data)
        logger.info("‚úÖ Data splits created:")
        logger.info(f"   üìö Train: {len(train_data)} samples ({len(train_data)/len(full_data)*100:.1f}%)")
        logger.info(f"   üìñ Validation: {len(val_data)} samples ({len(val_data)/len(full_data)*100:.1f}%)")
        logger.info(f"   üìã Test: {len(test_data)} samples ({len(test_data)/len(full_data)*100:.1f}%)")

        logger.info("üèóÔ∏è  Creating datasets...")
        train_dataset = ImprovedTemporalDataset(train_data, Config, mode='train')
        val_dataset = ImprovedTemporalDataset(val_data, Config, mode='val')
        test_dataset = ImprovedTemporalDataset(test_data, Config, mode='test')

        logger.info("‚ö° Creating train sampler for class balancing...")
        train_sampler = create_balanced_sampler(train_dataset)

        logger.info("‚ö° Creating data loaders...")
        train_loader = DataLoader(
            train_dataset,
            batch_size=Config.batch_size,
            sampler=train_sampler,
            drop_last=True,
            num_workers=Config.num_workers if hasattr(Config, 'num_workers') else 4,
        )
        val_loader = create_improved_data_loader(val_dataset, Config.batch_size)
        test_loader = create_improved_data_loader(test_dataset, Config.batch_size)

        logger.info("‚úÖ Data loaders created:")
        logger.info(f"   üöÇ Train: {len(train_loader)} batches")
        logger.info(f"   üöÉ Validation: {len(val_loader)} batches")
        logger.info(f"   üöÑ Test: {len(test_loader)} batches")

        logger.info("‚öñÔ∏è  Computing class weights (for logging only)...")
        class_weights = train_dataset.get_class_weights()
        logger.info(f"   Class weights: {class_weights}")

        return train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader, class_weights
    except Exception as e:
        logger.error(f"‚ùå Error creating datasets: {e}")
        raise


def create_and_setup_model(logger: logging.Logger):
    logger.info("\n" + "="*50)
    logger.info("üß† MODEL CREATION AND SETUP")
    logger.info("="*50)
    try:
        logger.info("üèóÔ∏è  Creating enhanced multimodal model...")
        model = ImprovedMultimodalModel(Config).to(Config.device)
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        logger.info("‚úÖ Model created successfully:")
        logger.info(f"   üìä Total parameters: {total_params:,}")
        logger.info(f"   üéØ Trainable parameters: {trainable_params:,}")
        logger.info(f"   üíæ Model size (MB): {total_params * 4 / (1024**2):.2f}")
        logger.info(f"   üéÆ Device: {next(model.parameters()).device}")
        return model
    except Exception as e:
        logger.error(f"‚ùå Error creating model: {e}")
        raise


def validate_data_loader(data_loader, logger):
    for batch_idx, batch in enumerate(data_loader):
        for key, tensor in batch.items():
            if isinstance(tensor, torch.Tensor):
                if torch.isnan(tensor).any():
                    logger.error(f"NaN detected in {key} at batch {batch_idx}")
                    raise ValueError("NaN detected in input data.")
                if torch.isinf(tensor).any():
                    logger.error(f"Inf detected in {key} at batch {batch_idx}")
                    raise ValueError("Inf detected in input data.")
                if tensor.abs().max() > 1e6:
                    logger.warning(f"Extreme value in {key} at batch {batch_idx}: max={tensor.abs().max()}")


def train_model(model, train_loader, val_loader, class_weights, logger: logging.Logger):
    logger.info("\n" + "="*50)
    logger.info("üöÄ MODEL TRAINING")
    logger.info("="*50)
    try:
        logger.info("üèãÔ∏è  Validating training data...")
        validate_data_loader(train_loader, logger)
        validate_data_loader(val_loader, logger)

        logger.info("üèãÔ∏è  Initializing enhanced trainer...")
        trainer = ImprovedTrainer(model, Config)
        logger.info("üöÄ Starting training process...")
        logger.info(f"   üìà Max epochs: {Config.num_epochs}")
        logger.info(f"   üìö Training batches: {len(train_loader)}")
        logger.info(f"   üìñ Validation batches: {len(val_loader)}")
        history = trainer.train(train_loader, val_loader, class_weights)
        logger.info("üìä Creating training visualization...")
        trainer.plot_training_history()
        logger.info("üèÜ Loading best performing model...")
        trainer.load_best_model()
        logger.info("‚úÖ Training completed successfully!")
        return trainer, history
    except Exception as e:
        logger.error(f"‚ùå Error during training: {e}")
        raise


def evaluate_model(model, test_loader, logger: logging.Logger):
    logger.info("\n" + "="*50)
    logger.info("üéØ MODEL EVALUATION")
    logger.info("="*50)
    try:
        logger.info("üîç Initializing enhanced evaluator...")
        evaluator = ImprovedEvaluator(model, Config)
        logger.info("üìä Evaluating model performance...")
        evaluation_results = evaluator.evaluate(test_loader)
        return evaluation_results
    except Exception as e:
        logger.error(f"‚ùå Error during evaluation: {e}")
        raise


def log_final_results(evaluation_results, logger: logging.Logger):
    logger.info("\n" + "="*60)
    logger.info("üéâ FINAL PERFORMANCE SUMMARY")
    logger.info("="*60)
    logger.info(f"üéØ Final Test Accuracy: {evaluation_results['accuracy']:.4f}")
    logger.info(f"üéØ Final Test F1 (Weighted): {evaluation_results['f1_weighted']:.4f}")
    logger.info(f"üéØ Final Test F1 (Macro): {evaluation_results['f1_macro']:.4f}")

    f1_weighted = evaluation_results['f1_weighted']
    if f1_weighted >= 0.9:
        logger.info("üéâ EXCELLENT performance! Model is ready for deployment consideration.")
    elif f1_weighted >= 0.8:
        logger.info("üëç GOOD performance! Some improvements may still be beneficial.")
    elif f1_weighted >= 0.7:
        logger.info("üëå ACCEPTABLE performance, but significant improvements needed.")
    else:
        logger.info("‚ö†Ô∏è  POOR performance. Major improvements required.")

    logger.info("\nüè• CLINICAL CONSIDERATIONS:")
    precision_per_class = evaluation_results.get('precision_per_class', [])
    recall_per_class = evaluation_results.get('recall_per_class', [])
    class_names = ['Depression', 'Mania', 'Euthymia']

    for i, class_name in enumerate(class_names):
        if i < len(precision_per_class) and i < len(recall_per_class):
            precision = precision_per_class[i]
            recall = recall_per_class[i]
            logger.info(f"   {class_name}:")
            logger.info(f"     Precision: {precision:.3f}")
            logger.info(f"     Recall: {recall:.3f}")
            if recall < 0.8:
                logger.info(f"     ‚ö†Ô∏è  Low sensitivity - may miss {class_name.lower()} cases")
            if precision < 0.8:
                logger.info(f"     ‚ö†Ô∏è  Low precision - may cause false {class_name.lower()} alarms")

    logger.info("\nüìã RECOMMENDED NEXT STEPS:")
    logger.info("1. üîç Review confusion matrix for specific error patterns")
    logger.info("2. üìä Analyze high-confidence errors for model insights")
    logger.info("3. üë©‚Äç‚öïÔ∏è Consider clinical validation with expert review")
    logger.info("4. üìà Implement model monitoring in production environment")
    logger.info("5. üîÑ Plan for continuous model updates with new data")
    logger.info("6. üõ°Ô∏è  Establish safety protocols and human oversight")
    logger.info("7. üìã Document model limitations and usage guidelines")


def save_results(comprehensive_results, history, logger: logging.Logger):
    safe_results = comprehensive_results.copy() if isinstance(comprehensive_results, dict) else comprehensive_results

    if 'config' in safe_results:
        cfg = safe_results['config']
        safe_results['config'] = {k: v for k, v in cfg.__dict__.items() if not k.startswith('__')}

    try:
        with open('evaluation_results.pkl', 'wb') as f:
            pickle.dump(safe_results, f)
        logger.info("‚úÖ Evaluation results saved successfully")
    except Exception as e:
        logger.error(f"‚ùå Failed to save evaluation results: {e}")

    try:
        with open('training_history.pkl', 'wb') as f:
            pickle.dump(history, f)
        logger.info("‚úÖ Training history saved successfully")
    except Exception as e:
        logger.error(f"‚ùå Failed to save training history: {e}")


def main():
    logger = setup_logging()

    try:
        setup_environment(logger)
        full_data, data_analysis = load_and_analyze_data(logger)
        train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader, class_weights = create_datasets_and_loaders(full_data, logger)
        model = create_and_setup_model(logger)
        trainer, history = train_model(model, train_loader, val_loader, class_weights, logger)
        evaluation_results = evaluate_model(model, test_loader, logger)
        log_final_results(evaluation_results, logger)
        save_results(evaluation_results, history, logger)
        logger.info("\n" + "="*60)
        logger.info("‚úÖ ENHANCED BD DETECTION PIPELINE COMPLETED SUCCESSFULLY!")
        logger.info("="*60)
        logger.info("üéØ You can now proceed with clinical validation and deployment considerations.")
        logger.info("üìä Check the generated plots and saved results for detailed analysis.")
        return evaluation_results, history

    except Exception as e:
        logger.error(f"‚ùå Pipeline failed: {e}")
        logger.error("üí° Please check the logs for detailed error information.")
        raise

    finally:
        logger.info("üèÅ Pipeline execution finished.")


if __name__ == "__main__":
    results, history = main()
    print("\n" + "="*60)
    print("üéâ ENHANCED BD DETECTION PIPELINE EXECUTION COMPLETE")
    print("="*60)
    print(f"üìä Final Results Summary:")
    print(f"   Accuracy: {results.get('accuracy', 'N/A'):.4f}")
    print(f"   F1 (Weighted): {results.get('f1_weighted', 'N/A'):.4f}")
    print(f"   F1 (Macro): {results.get('f1_macro', 'N/A'):.4f}")
    print("üìÇ Check saved files for detailed results and visualizations.")
